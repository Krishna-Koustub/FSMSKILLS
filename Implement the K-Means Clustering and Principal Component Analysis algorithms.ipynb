{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0d668a",
   "metadata": {},
   "source": [
    "Implement the K-Means Clustering and Principal Component Analysis algorithms from scratch in Python using Numpy and Pandas and Matplotlib for visualization.\n",
    "\n",
    "The algorithm must be implemented as a function with arguments (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d158b692",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3549128650.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    def initialize_centroids(Iris Dataset, k):\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def k_means_clustering(dataset, k=3, n_init=10, max_iter=300):\n",
    "    # Define a function to calculate the Euclidean distance between two points\n",
    "    def euclidean_distance(x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    \n",
    "    # Define a function to initialize the centroids\n",
    "    def initialize_centroids(Iris Dataset, k):\n",
    "        centroids = dataset.copy()\n",
    "        np.random.shuffle(centroids)\n",
    "        return centroids[:k]\n",
    "    \n",
    "    # Define a function to assign each data point to the closest centroid\n",
    "    def assign_clusters(dataset, centroids):\n",
    "        clusters = []\n",
    "        for i in range(len(dataset)):\n",
    "            distances = [euclidean_distance(dataset[i], centroid) for centroid in centroids]\n",
    "            cluster = np.argmin(distances)\n",
    "            clusters.append(cluster)\n",
    "        return clusters\n",
    "    \n",
    "    # Define a function to update the centroids based on the mean of the assigned data points\n",
    "    def update_centroids(dataset, clusters, k):\n",
    "        centroids = np.zeros((k, dataset.shape[1]))\n",
    "        for i in range(k):\n",
    "            centroids[i] = np.mean(dataset[clusters == i], axis=0)\n",
    "        return centroids\n",
    "    \n",
    "    # Initialize the best cost and best centroids\n",
    "    best_cost = float('inf')\n",
    "    best_centroids = None\n",
    "    \n",
    "    # Run the K-Means algorithm multiple times with different initializations\n",
    "    for i in range(n_init):\n",
    "        # Initialize the centroids\n",
    "        centroids = initialize_centroids(dataset, k)\n",
    "        \n",
    "        # Run the K-Means algorithm\n",
    "        for j in range(max_iter):\n",
    "            # Assign each data point to the closest centroid\n",
    "            clusters = assign_clusters(dataset, centroids)\n",
    "            \n",
    "            # Update the centroids based on the mean of the assigned data points\n",
    "            new_centroids = update_centroids(dataset, clusters, k)\n",
    "            \n",
    "            # Check if the centroids have changed\n",
    "            if np.all(centroids == new_centroids):\n",
    "                break\n",
    "            \n",
    "            # Update the centroids\n",
    "            centroids = new_centroids\n",
    "        \n",
    "        # Calculate the cost of the current solution\n",
    "        cost = 0\n",
    "        for i in range(len(dataset)):\n",
    "            cost += euclidean_distance(dataset[i], centroids[clusters[i]]) ** 2\n",
    "        \n",
    "        # Check if the current solution is better than the best solution found so far\n",
    "        if cost < best_cost:\n",
    "            best_cost = cost\n",
    "            best_centroids = centroids\n",
    "    \n",
    "    # Return the best solution found\n",
    "    return assign_clusters(dataset, best_centroids), best_centroids\n",
    "\n",
    "def principal_component_analysis(dataset):\n",
    "    # Calculate the mean of each feature\n",
    "    mean = np.mean(dataset, axis=0)\n",
    "    \n",
    "    # Center the data by subtracting the mean from each data point\n",
    "    centered_data = dataset - mean\n",
    "    \n",
    "    # Calculate the covariance matrix of the centered data\n",
    "    covariance_matrix = np.cov(centered_data.T)\n",
    "    \n",
    "    # Calculate the eigenvalues and eigenvectors of the covariance matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "    \n",
    "    # Sort the eigenvalues and eigenvectors in descending order of eigenvalue magnitude\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    \n",
    "    # Project the data onto the first three principal components\n",
    "    projected_data = centered_data.dot(eigenvectors[:, :3])\n",
    "    \n",
    "    return projected_data, eigenvalues[:3]\n",
    "\n",
    "# Load and prepare the Iris dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])\n",
    "species_column=data['target']\n",
    "dataset=data.drop('target',axis=1)\n",
    "\n",
    "# Perform K-Means Clustering on the Iris dataset\n",
    "clusters, _ = k_means_clustering(dataset.values)\n",
    "\n",
    "# Perform Principal Component Analysis on the Iris dataset\n",
    "projected_data, eigenvalues = principal_component_analysis(dataset.values)\n",
    "\n",
    "# Create a 3D scatter plot to visualize the results of Principal Component Analysis and K-Means Clustering\n",
    "\n",
    "fig=plt.figure(figsize=(15,5))\n",
    "ax1=fig.add_subplot(131,projection='3d')\n",
    "ax1.scatter(projected_data[:, 0], projected_data[:, 1], projected_data[:, 2], c=clusters)\n",
    "ax1.set_title('K-Means Clustering')\n",
    "ax1.set_xlabel('PC1')\n",
    "ax1.set_ylabel('PC2')\n",
    "ax1.set_zlabel('PC3')\n",
    "\n",
    "ax2=fig.add_subplot(132)\n",
    "ax2.bar(['PC1', 'PC2', 'PC3'], eigenvalues)\n",
    "ax2.set_title('Principal Component Analysis')\n",
    "ax2.set_ylabel('Eigenvalue')\n",
    "\n",
    "ax3=fig.add_subplot(133,projection='3d')\n",
    "ax3.scatter(projected_data[:, 0], projected_data[:, 1], projected_data[:, 2], c=species_column)\n",
    "ax3.set_title('Actual Species')\n",
    "ax3.set_xlabel('PC1')\n",
    "ax3.set_ylabel('PC2')\n",
    "ax3.set_zlabel('PC3')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16a84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e0ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
